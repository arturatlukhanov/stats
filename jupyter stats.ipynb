{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import ast\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "from sshtunnel import SSHTunnelForwarder\n",
    "from sqlalchemy import create_engine\n",
    "from datetime import datetime, timedelta\n",
    "import asyncio\n",
    "import asyncpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получаем текущую дату\n",
    "current_datetime = datetime.now()\n",
    "current_datetime = current_datetime - timedelta(days=1)\n",
    "current_datetime_minus_1_day = (current_datetime).strftime('%Y-%m-%d')\n",
    "\n",
    "current_datetime_m = current_datetime.replace(day=1).strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Читаем данные с файлов\n",
    "raw_data = pd.read_csv(f' /sql/state_data/{current_datetime_m}/raw_in_app_events.csv', sep=',')\n",
    "raw_data_retarget = pd.read_csv(f' /sql/state_data/{current_datetime_m}/raw_in_app_events_retarget.csv', sep=',')\n",
    "fraud_data = pd.read_csv(f' /sql/state_data/{current_datetime_m}/fraud_post_attribution_installs.csv', sep=',')\n",
    "offers_by_accounts_offers = pd.read_excel(' /sql/offers_by_accounts.xlsx', sheet_name = 'offers')\n",
    "offers_by_accounts_VTA = pd.read_excel(' /sql/offers_by_accounts.xlsx', sheet_name = 'VTA')\n",
    "appmetrica = pd.read_csv(' /sql/state_data/appmetrica/appmetrica.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = input(\n",
    "    '''\n",
    "    Нажмите q для нового отчёта и отправки на сервер\n",
    "    или любой символ для заполнения сеток\n",
    "    '''\n",
    ")\n",
    "# stats_offers_mode = input(\n",
    "#     '''\n",
    "#     Нажмите w для отправки в Google Sheets\n",
    "#     или любой символ для заполнения сеток\n",
    "#     '''\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#============================================================================================================================================================= \n",
    "\n",
    "# Зарубежные бренды\n",
    "CIS_brand = ['XM','Binance','Kindred Group','Bet365']\n",
    "\n",
    " # Удаляем дубликаты в по этим столбцам (дубликаты уникальных сочетаний этих столбцов)\n",
    "columns_to_check_offers = ['App_Id', 'Offer_Name', 'Brand', 'Event_Name', 'Media_Source', 'geo', 'cpa', 'curr']\n",
    "offers_by_accounts_offers = offers_by_accounts_offers.drop_duplicates(subset=columns_to_check_offers)\n",
    "\n",
    " # Список апп айди брендов в которых нужно оставить гео только RU\n",
    "Geo_RU_Only_brand = ['id579961527','ru.stoloto.mobile-allstores','id1038254296','com.carshering','id1265056713','ru.bistrodengi.my']\n",
    "\n",
    "# ,'Anytime KZ','Anytime BY','id1415669951','kz.anytime.mobile.android','id1231153647','by.drivetime.app'\n",
    "\n",
    " # Бренды ЮА в которых нужно оставить гео только RU ('Столото','Delimobil','Bystrodengi')\n",
    "raw_data = raw_data[~((raw_data['App_ID_clear'].isin(Geo_RU_Only_brand)) & (raw_data['Country_Code']!='RU'))]\n",
    "\n",
    " # Бренды ретаргета в которых нужно оставить гео только RU ('Столото ретаргет','Delimobil ретаргет')\n",
    "raw_data_retarget = raw_data_retarget[~((raw_data_retarget['App_ID_clear'].isin(Geo_RU_Only_brand)) & (raw_data_retarget['Country_Code']!='RU'))]\n",
    "\n",
    "# Обработка Fonbet. Удаляем строки, в которых по столбцу Sub_Param_1 пусто. Таково условие фонебета по инаппу.\n",
    "raw_data = raw_data[~((raw_data['Sub_Param_1']==\"\") & (raw_data['App_ID_clear'].isin(['id1166619854','ru.bkfon-Android'])))]\n",
    "\n",
    "# Оставляем только нужные гео по юнибету\n",
    "raw_data = raw_data[~((raw_data['App_ID_clear'].isin(['id905382680','com.unibet.casino','id463335337','com.unibet.unibetpro','id570198108']))\\\n",
    "    & ~(raw_data['Country_Code'].isin(['RO','UK','SE'])))]\n",
    "\n",
    "#\n",
    "# print(raw_data[raw_data['App_ID_clear'].isin(['ru.tander.magnit', 'id881463973'])]['App_ID'].count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    " # добавляем в название апп айди обозначение ретаргета так, чтобы затем можно было мерджить данные с офферс бай аккаунта\n",
    "raw_data_retarget['App_ID'] = raw_data_retarget['App_ID'].apply(lambda x: f\"{x[:-2]}reattr{x[-2:]}\")\n",
    "\n",
    " # Объединяем данные ретаргета и ЮА\n",
    "raw_data = pd.concat([raw_data, raw_data_retarget], axis=0, ignore_index=True)\n",
    "\n",
    "# Изменяем формат полей, чтобы затем вычесть их друг от друга и получить окно атрибуции\n",
    "raw_data['Event_Time'] = pd.to_datetime(raw_data['Event_Time'])\n",
    "raw_data['Install_Time'] = pd.to_datetime(raw_data['Install_Time'])\n",
    "raw_data['Atribution'] = (raw_data['Event_Time'] - raw_data['Install_Time']).dt.days\n",
    "\n",
    " # Делаем сортировку данных по дате конверсии, чтобы затем удалить фрод и окно атрибуции в нашу пользу\n",
    "raw_data.sort_values(by='Atribution', ascending=True, inplace=True)\n",
    "\n",
    "raw_data = raw_data[raw_data['Partner'].isin(['Wakeapp','wakeapppartners','hrngloballcy118', 'adpromarkebg511', 'wakerockmobile', 'mobiadsru988'])] \n",
    "fraud_data = fraud_data[fraud_data['Partner'].isin(['Wakeapp','wakeapppartners','hrngloballcy118', 'adpromarkebg511', 'wakerockmobile', 'mobiadsru988'])]\n",
    "\n",
    "# Обрабатываем поле для дальнейшего удаления дубликатов\n",
    "raw_data['AppsFlyer_ID'] = raw_data['AppsFlyer_ID'].str.strip()\n",
    "raw_data['AppsFlyer_ID'] = raw_data['AppsFlyer_ID'].str.replace(r'\\s+', '', regex=True)\n",
    "raw_data['AppsFlyer_ID'] = raw_data['AppsFlyer_ID'].str.strip().str.lower()\n",
    "\n",
    "# Обрабатываем поле для дальнейшего удаления дубликатов\n",
    "fraud_data['AppsFlyer_ID'] = fraud_data['AppsFlyer_ID'].str.strip()\n",
    "fraud_data['AppsFlyer_ID'] = fraud_data['AppsFlyer_ID'].str.replace(r'\\s+', '', regex=True)\n",
    "fraud_data['AppsFlyer_ID'] = fraud_data['AppsFlyer_ID'].str.strip().str.lower()\n",
    "\n",
    "# Удаляем Дубликаты\n",
    "raw_data = raw_data.dropna(subset=['AppsFlyer_ID'])\n",
    "raw_data = raw_data.drop_duplicates(subset=['AppsFlyer_ID','Event_Name','App_ID_clear'])\n",
    "fraud_data = fraud_data.dropna(subset=['AppsFlyer_ID'])\n",
    "fraud_data = fraud_data.drop_duplicates(subset=['AppsFlyer_ID','Event_Name','App_ID_clear'])\n",
    "\n",
    "#raw_data.to_csv(' /sql/state_data/raw_data.csv', index=False)\n",
    "#fraud_data.to_csv(' /sql/state_data/fraud_data.csv', index=False)\n",
    "\n",
    "#raw_data.to_csv(' /sql/state_data/raw_data_without_duplicates1.csv', index=False)\n",
    "\n",
    "# Отмечаем фрод\n",
    "raw_data['Fraud'] = raw_data['AppsFlyer_ID'].isin(fraud_data['AppsFlyer_ID']).astype(int)\n",
    "raw_data_with_fraud = raw_data\n",
    "\n",
    "# Переименовывается поле\n",
    "offers_by_accounts_VTA.rename(columns={'App_Id':'App_ID'}, inplace=True)\n",
    "\n",
    "# Происходит объединение наших данных с листом окна атрибуции, чтобы затем убрать данные, которые больше окна атрибуции\n",
    "raw_data_VTA_merge = pd.merge(raw_data_with_fraud, offers_by_accounts_VTA, on='App_ID', how = 'left')\n",
    "\n",
    "# Удаляем дубли по полю аф айди\n",
    "raw_data_VTA_merge['AppsFlyer_ID'] = raw_data_VTA_merge['AppsFlyer_ID'].drop_duplicates()\n",
    "\n",
    "# Удаляем данные переходящие за окно атрибуции \n",
    "#raw_data_VTA_merge.to_csv(' /sql/state_data/raw_data_VTA_merge.csv', index=False)\n",
    "raw_data_VTA_merge = raw_data_VTA_merge[raw_data_VTA_merge['Atribution'] < raw_data_VTA_merge['VTA']]\n",
    "\n",
    "# Переименовывается поле\n",
    "raw_data_VTA_merge.rename(columns={'Country_Code':'geo'}, inplace=True)\n",
    "# Переименовывается поле\n",
    "offers_by_accounts_offers.rename(columns={'App_Id':'App_ID'}, inplace=True)\n",
    "\n",
    "# У российских брендов в гео все заменяется на RU в двух таблицах, чтобы затем таблицы правильно сопоставлялись без потери данных,\n",
    "#  так как объединение затем будет в том числе по ключу \n",
    "offers_by_accounts_offers['geo'] = np.where(offers_by_accounts_offers['Brand'].isin(CIS_brand), offers_by_accounts_offers['geo'],'RU')\n",
    "raw_data_VTA_merge['geo'] = np.where(raw_data_VTA_merge['Brand'].isin(CIS_brand), raw_data_VTA_merge['geo'],'RU')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#============================================================================================================================================================\n",
    "# Дополнительная обработка брендов \n",
    "\n",
    "# Delimobil\n",
    "raw_data_VTA_merge = raw_data_VTA_merge[~((raw_data_VTA_merge['Brand'].isin(['Delimobil', 'Delimobil ретаргет'])) & \\\n",
    "    (raw_data_VTA_merge['Is_Primary_Attribution'] == False))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Закомменченный код ниже нужен для проверки, что сопоставляет выгрузка по апи с офферс бай аккаунт а что нет - по значению only_left поля _merge, \n",
    "# можно понять что не сопоставляется, и не идет дальше в стату\n",
    "raw_data_offers_merge = pd.merge(raw_data_VTA_merge, offers_by_accounts_offers, on=['App_ID','Event_Name','geo'], how = 'left', indicator=True)\n",
    "#raw_data_offers_merge.to_csv(' /sql/state_data/raw_data_offers_merge.csv')\n",
    "#raw_data_VTA_merge.to_csv(' /sql/state_data/raw_data_VTA_merge_1.csv', index=False)\n",
    "\n",
    "# В значениях поля Event_Time оставляем только год месяц и день, без времени\n",
    "raw_data_VTA_merge['Event_Time'] = pd.to_datetime(raw_data_VTA_merge['Event_Time']).dt.date\n",
    "\n",
    "# Оставляем нужные столбцы для дальнейшей группировки\n",
    "raw_data_VTA_merge = raw_data_VTA_merge[['Partner','Platform','Media_Source','geo','App_ID','Event_Name','Event_Time','Offer_Name','Brand','Fraud']]\n",
    "\n",
    "# Группируем данные чтобы избежать дублирования данных при мердже\n",
    "raw_data_VTA_merge = raw_data_VTA_merge.groupby(['Partner','Platform', 'Media_Source','geo','App_ID',\\\n",
    "    'Event_Name','Event_Time','Offer_Name','Brand'], as_index=False).agg(Conversion=('App_ID', 'count'), Fraud=('Fraud', lambda x: x.sum()))\n",
    "\n",
    "# Объединение по ключам наших данных уже с учетом окна атрибуции с офферс бай аккаунт, чтобы вытащить ставки, бренд,\n",
    "# менеджера и очистка от данных, которых нет в офферс бай аккаунт \n",
    "raw_data_offers_merge = pd.merge(raw_data_VTA_merge, offers_by_accounts_offers, on=['App_ID','Event_Name','geo'], how = 'left')\n",
    "\n",
    "# raw_data_offers_merge.to_csv(' /sql/state_data/raw_data_offers_merge.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "# Оставляем необходимые колонки\n",
    "raw_data_offers_merge = raw_data_offers_merge[['Partner', 'Media_Source_x',\\\n",
    "    'Platform','App_ID', 'Event_Name', 'Event_Time',\\\n",
    "    'Offer_Name_y', 'Brand_y', 'cpa', 'curr', 'manager','geo','Fraud','Conversion']]\n",
    "\n",
    "# Переименновываем колонки после мерджа\n",
    "raw_data_offers_merge.rename(columns={'Media_Source_x':'Media_Source', 'Offer_Name_y':'Offer_Name', 'Brand_y':'Brand'}, inplace=True)\n",
    "\n",
    "# В значениях поля Event_Time оставляем только год месяц и день, без времени\n",
    "raw_data_offers_merge['Event_Time'] = pd.to_datetime(raw_data_offers_merge['Event_Time']).dt.date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пиды баинга (их нужно удалять только из аккаунта WA)\n",
    "lst_of_buying_pids = [\n",
    "    \"affiliate\", \"Apple Search Ads\", \n",
    "    \"bigoads_int\", \"bigo_int\", \"blog\", \"bytedanceglobal_int\", \"dv360\", \"dv360_int\", \"Exceeded_MediaSource_Limit\", \"Facebook Ads\", \n",
    "    \"facebook2\", \"facebook_int\", \"Facebook_int\", \"fb\", \"googleadwords_int\", \"google_int\", \"mail.ru_int\", \"None\", \"Organic\",\n",
    "    \"partner\", \"prelend\", \"snapchat_int\", \"taboola_int\", \"Telegram\", \"u\", \"union_fb\", \"union_google\", \"Wakeapp\", \"WakeApp_FB\", \n",
    "    \"yandexdirect_int\",  \"Blog\", \"telegram\", \"meta360s_int\", \"Blog1\", \"Blog2\", \"Blog3\", \"Blog5\", \"Blog 4\", \n",
    "    \"Blog6\", \"huaweiadsglobal_int\", \"hybrid_int\", \"dataliftretargeting_int\", \"liftoff_int\", \"moloco_int\", \"appier_int\", \"appreciateappoffers_int\", \n",
    "    \"wakeappdsp_int\", \"thetradedesk_int\", \"yahoogemini_int\", \"applovin_int\", \"slikklabs_int\",  \"adcolony_int\", \"jampp_int\",\"jampp_int\" \n",
    "    \"personalyrtb_int\",  \"unity_int\", 'app7', 'app8', 'app9', 'Blog7',\"tjzymob_int\", \"cherishads_int\", \"appnext_int\",\n",
    "    \"decho_int\" , \"unityads_int\",\"Mintegral\", \"mintegral\", \"mintegral_int\", \"vungle_int\", 'unityads_int',\"ironsource_int\", \"unityads_int\", \"xiaomiglobal_int\"\n",
    "\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Тут устраняются пиды баинга из выгрузок аккаунта Wakeapp (WA), потому что именно тут это является баингом\n",
    "raw_data_offers_merge = raw_data_offers_merge[~((raw_data_offers_merge['Partner'] == 'Wakeapp') & \\\n",
    "    (raw_data_offers_merge['Media_Source'].isin(lst_of_buying_pids)))]\n",
    "\n",
    "# Выбираем нужные нам поля\n",
    "raw_data_offers_merge = raw_data_offers_merge[['Partner', 'Media_Source', 'geo',\\\n",
    "    'Platform','App_ID', 'Event_Name','Event_Time',\\\n",
    "    'Offer_Name', 'Brand', 'cpa', 'curr','manager','Fraud','Conversion']]\n",
    "\n",
    "# Устраняются пробелы в поле медиа сорс\n",
    "raw_data_offers_merge['Media_Source'] = raw_data_offers_merge['Media_Source'].str.strip()\n",
    "\n",
    "# Оставляем только те строки, в которых гео не равно RU\n",
    "dozap_geo = raw_data_offers_merge[raw_data_offers_merge['geo'] != 'RU'] \n",
    "# Оставляем только те строки, в которых гео равно RU\n",
    "dozap_no_geo = raw_data_offers_merge[raw_data_offers_merge['geo'] == 'RU']\n",
    "\n",
    "# Выбираем нужные нам поля\n",
    "dozap_geo_ = dozap_geo[['Offer_Name','Media_Source','Event_Name','geo','Brand']]\n",
    "# Выбираем нужные нам поля\n",
    "dozap_no_geo_ = dozap_no_geo[['Offer_Name','Media_Source','Event_Name','geo','Brand']]\n",
    "\n",
    "# Группируем данные для сокращения объемов данных для дальнеших операций \n",
    "merge_geo_dozap = dozap_geo_.groupby(['Offer_Name','Media_Source','Event_Name','geo'], as_index=False).count()\n",
    "# Группируем данные для сокращения объемов данных для дальнеших операций \n",
    "merge_dozap = dozap_no_geo_.groupby(['Offer_Name','Media_Source','Event_Name','geo'], as_index=False).count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Читаем данные из листа файла по заполненным сеткам зарубежных брендов\n",
    "Networks_geo = pd.read_excel(' /sql/networks.xlsx', sheet_name = 'Networks_Geo')\n",
    "# Читаем данные из листа файла по заполненным сеткам российских брендов\n",
    "Networks = pd.read_excel(' /sql/networks.xlsx', sheet_name = 'Networks')\n",
    "\n",
    "# Тут создается список названий полей, которые дальше будут использованы для удаления дублей\n",
    "columns_to_check_networks = ['Offer_Name', 'Media_Source', 'network_name', 'affiliate', 'Event_Name', 'payout', 'geo']\n",
    "\n",
    "# Тут удаляются дубли по полям которые переданы переменной (удаляются дублирующие значения именно по сочетанию значений всех строк этих полей)\n",
    "Networks_geo = Networks_geo.drop_duplicates(subset=columns_to_check_networks)\n",
    "Networks = Networks.drop_duplicates(subset=columns_to_check_networks)\n",
    "\n",
    "# Объединение данных из нашей выгрузи и данных в нетворкс, чтобы наши данные получили ставки, название сетки и афилейта.\n",
    "raw_data_Networks_geo = pd.merge(merge_geo_dozap, Networks_geo, on=['Offer_Name', 'Media_Source', 'geo','Event_Name',], how = 'left', indicator=True)\n",
    "raw_data_Networks = pd.merge(merge_dozap, Networks, on=['Offer_Name', 'Media_Source','Event_Name',], how = 'left', indicator=True)\n",
    "\n",
    "# Оставляем только те значения, которые не сопоставились при объединении - те которых нет в нетворксе\n",
    "raw_data_Networks_geo_dozap = raw_data_Networks_geo[raw_data_Networks_geo['_merge'] == 'left_only']\n",
    "raw_data_Networks_dozap = raw_data_Networks[raw_data_Networks['_merge'] == 'left_only']\n",
    "\n",
    "# Объединяем данные с гео и без гео, которые не сопоставились \n",
    "for_dozap = pd.concat([raw_data_Networks_geo_dozap, raw_data_Networks_dozap], axis = 0, ignore_index=True)\n",
    "for_dozap.rename(columns={'Event_Name_x':'Event_Name'}, inplace=True)\n",
    "\n",
    "# оставляем нужные нам столбцы в несопоставиленных данных.\n",
    "for_dozap = for_dozap[['Offer_Name', 'Media_Source', 'network_name', 'affiliate', 'Event_Name', 'payout', 'geo']]\n",
    "for_dozap['geo'] = for_dozap['geo'].replace(['', 'NAN'], 'RU').fillna('RU')\n",
    "\n",
    "# Выгружаем несопоставленные данные, для заполнения нетворкса. \n",
    "for_dozap.to_excel(' /sql/state_data/for_dozap.xlsx', index=False)\n",
    "\n",
    "# Тут мы выделяем данные которые сопоставились, и отправляем их дальше по обработке \n",
    "raw_data_Networks_geo_good = raw_data_Networks_geo[raw_data_Networks_geo['_merge'] == 'both']\n",
    "raw_data_Networks_good = raw_data_Networks[raw_data_Networks['_merge'] == 'both']\n",
    "\n",
    "# Объединяем даные с гео и без гео, переименовываем столбцы, оставляем только нужные нам. Дальше мы будем эти данные объединять с нашими сырыми.\n",
    "dozap_good = pd.concat([raw_data_Networks_geo_good, raw_data_Networks_good], axis = 0, ignore_index=True)\n",
    "dozap_good.rename(columns={'Event_Name_x':'Event_Name'}, inplace=True)\n",
    "dozap_good = dozap_good[['Offer_Name', 'Media_Source', 'network_name', 'affiliate', 'Event_Name', 'payout', 'geo']]\n",
    "# Создаем список столбцов которые пойдут для удаленния дубликатов\n",
    "columns_to_check = ['Offer_Name', 'Media_Source', 'network_name', 'affiliate', 'Event_Name', 'payout', 'geo']\n",
    "dozap_good = dozap_good.drop_duplicates(subset=columns_to_check)\n",
    "\n",
    "# Вместо пустых строк, вставляем гео RU \n",
    "dozap_good['geo'] = dozap_good['geo'].replace(['', 'NAN'], 'RU').fillna('RU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Здесь группируются наши более сырые данные, не прошедшие через прошлую ячейку - где данные отправились в дозаполнение сеток.\n",
    "dozap_good_geo_group = dozap_geo.groupby(['Event_Time','Partner','Brand','Offer_Name','App_ID','Platform','Media_Source','Event_Name',\\\n",
    "    'cpa', 'curr', 'manager','geo'], as_index=False).agg(Conversion=('Conversion', 'sum'), Fraud=('Fraud', 'sum'))\n",
    "\n",
    "dozap_good_group = dozap_no_geo.groupby(['Event_Time','Partner','Brand','Offer_Name','App_ID','Platform','Media_Source','Event_Name',\\\n",
    "    'cpa', 'curr', 'manager','geo'], as_index=False).agg(Conversion=('Conversion', 'sum'), Fraud=('Fraud', 'sum'))\n",
    "\n",
    "\n",
    "# dozap_good_geo_group.to_csv(' /sql/state_data/dozap_good_geo_group.csv', index=False)\n",
    "\n",
    "#Объединяем наши сгруппированные данные с теми что со ставками\n",
    "dozap_good_merge_geo = pd.merge(dozap_good_geo_group, dozap_good, on=['Offer_Name', 'Media_Source', 'Event_Name','geo'], how='left', indicator='merge_status')\n",
    "\n",
    "dozap_good_merge = pd.merge(dozap_good_group, dozap_good, on=['Offer_Name', 'Media_Source','Event_Name','geo'], how='left', indicator='merge_status')\n",
    "\n",
    "# dozap_good_merge_geo.to_csv(' /sql/state_data/dozap_good_geo_group.csv', index=False)\n",
    "\n",
    "# Объединияем наши данные с гео и без гео\n",
    "for_stats = pd.concat([dozap_good_merge_geo, dozap_good_merge], axis = 0, ignore_index=True)\n",
    "\n",
    "\n",
    "# Оставляем только те, которые которые конектнулись при мердже\n",
    "for_stats = for_stats[for_stats['merge_status'] == 'both']\n",
    "\n",
    "# Оставляем нужные нам строки только\n",
    "for_stats = for_stats[['Event_Time','Partner','Brand','Offer_Name','App_ID','Platform', 'Media_Source',\\\n",
    "     'Event_Name', 'manager','cpa', 'curr', 'affiliate', 'network_name', 'payout','geo','Conversion','Fraud']]\n",
    "\n",
    "# Заполняем пустые значения по полю гео, превращая это в RU \n",
    "for_stats['geo'] = for_stats['geo'].replace(['', 'NAN'], 'RU').fillna('RU')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#============================================================================================================================================================================\n",
    "# Фонбет (Fonbet) считается\n",
    "\n",
    "# Оставляем только фонбет где сорсы adcolony\n",
    "for_stats = for_stats[(for_stats['Brand'] != 'Фонбет') | ((for_stats['Brand'] == 'Фонбет') & (for_stats['Media_Source'].isin(['adcolony_int', 'adcolony'])))]\n",
    "\n",
    "# выставляем ставку фонбета где сорсы adcolony\n",
    "for_stats['cpa'] = np.where(\n",
    "    ((for_stats['Brand'] == 'Фонбет') & \n",
    "     (for_stats['Media_Source'].isin(['adcolony_int', 'adcolony'])) & \n",
    "     ((for_stats['Event_Name'] == 'af_baseline2'))), \n",
    "    16000, \n",
    "    for_stats['cpa']\n",
    ")\n",
    "\n",
    "for_stats['cpa'] = np.where(\n",
    "    ((for_stats['Brand'] == 'Фонбет') & \n",
    "     (for_stats['Media_Source'].isin(['adcolony_int', 'adcolony'])) & \n",
    "     ((for_stats['Event_Name'] == 'af_ftd'))), \n",
    "    10000, \n",
    "    for_stats['cpa']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавляем данные из аппметрики\n",
    "for_stats = pd.concat([for_stats, appmetrica], axis=0, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выгружаем данные из файла с ставками и валютами\n",
    "currencies = pd.read_excel(r\"G:\\.shortcut-targets-by-id\\1-0y0YvUdxNOM5ZnhM4sE0iJVter1OKIh\\тест\\ИнАпп\\ЦБ инапп.xlsm\").tail(1).reset_index(drop=True)\n",
    "\n",
    "# Тут мы обходим по валютам и ставкам которые не в евро, и соответственно переводим в евро\n",
    "# Преобразуем 'curr' в массив для работы с масками\n",
    "def current_eur(row):\n",
    "    if row['curr'] == 'RUB':\n",
    "        return row['cpa'] / currencies['EUR'].iloc[0]\n",
    "    elif row['curr'] == 'USD':\n",
    "        return row['cpa'] / currencies['USD-EUR'].iloc[0]\n",
    "    elif row['curr'] == 'GBP':\n",
    "        return row['cpa'] * currencies['GBP-EUR'].iloc[0]\n",
    "    else:\n",
    "        return row['cpa']  # Если валюта уже EUR\n",
    "\n",
    "# Создаем столбец в котором переводим \n",
    "for_stats['cpa_eur'] = for_stats.apply(current_eur, axis=1)\n",
    "\n",
    "# Применяем множители на основе значений в 'curr'\n",
    "for_stats['payout_eur'] = for_stats['payout']/currencies['USD-EUR'].iloc[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем чистые ивенты\n",
    "for_stats['Pure_Conversion'] = for_stats['Conversion'] - for_stats['Fraud']\n",
    "# Чистые ивенты которые пустые - те что из аппметрики ибо там нет фрода, заполняем данными из Conversion\n",
    "for_stats['Pure_Conversion'] = for_stats['Pure_Conversion'].fillna(for_stats['Conversion'])\n",
    "# Создаем евро бюджет, затем расходы, и затем профит\n",
    "for_stats['Budget'] = for_stats['cpa_eur'] * for_stats['Pure_Conversion']\n",
    "for_stats['Cost'] = for_stats['payout_eur'] * for_stats['Pure_Conversion']\n",
    "for_stats['Profit'] = for_stats['Budget'] - for_stats['Cost']\n",
    "\n",
    "# Оставляем нужные нам поля\n",
    "for_stats = for_stats[['Event_Time','Partner','Brand','Offer_Name','App_ID','Platform', 'Media_Source',\\\n",
    "    'Event_Name', 'manager','cpa', 'curr', 'cpa_eur', 'affiliate', 'network_name', 'payout','payout_eur',\\\n",
    "    'geo','Conversion','Fraud','Pure_Conversion','Budget','Cost','Profit']]\n",
    "\n",
    "# Формируем переменную в которую закидываем строки, которые содержат 0 или пустые по полям Cpa_eur - ставка которую платят нам в евро, и Payout_eur то что платим мы в евро\n",
    "for_stats_without_cpa_payout = for_stats[((for_stats['cpa_eur']== 0) | (for_stats['payout_eur']== 0) |\\\n",
    "    (for_stats['cpa_eur']== 0.0) | (for_stats['payout_eur']== 0.0) | (for_stats['payout_eur']== \"\") | (for_stats['cpa_eur']== \"\")\\\n",
    "    |(for_stats['payout_eur']== \" \") | (for_stats['cpa_eur']== \" \"))]\n",
    "\n",
    "# Сохраняем данные, чтобы изучить и устранить проблему либо в нетворкс либо в офферс бай аккаунт\n",
    "# for_stats_without_cpa_payout.to_csv(' /sql/state_data/for_stats_without_cpa_payout.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===================================================================================================================================================================\n",
    "# Тут исключаем поля которые по ставкам равны нулю\n",
    "#for_stats = for_stats[~((for_stats['cpa_eur']== 0) | (for_stats['payout_eur']== 0) & (for_stats['Brand']!= 'Bet365'))]\n",
    "\n",
    "# Тут обработка Фонбета обнуляем конверсии по регам, за которые нам не платят\n",
    "for_stats['Pure_Conversion'] = np.where((for_stats['Brand']=='Фонбет') & (for_stats['Event_Name']=='af_reg'), \\\n",
    "    for_stats['Pure_Conversion']== 0, for_stats['Pure_Conversion'])\n",
    "\n",
    "for_stats['Conversion'] = np.where((for_stats['Brand']=='Фонбет') & (for_stats['Event_Name']=='af_reg'), \\\n",
    "    for_stats['Conversion']== 0, for_stats['Conversion'])\n",
    "\n",
    "for_stats['Fraud'] = np.where((for_stats['Brand']=='Фонбет') & (for_stats['Event_Name']=='af_reg'), \\\n",
    "    for_stats['Fraud']== 0, for_stats['Fraud'])\n",
    "\n",
    "for_stats['Pure_Conversion'] = np.where(for_stats['Brand'] == 'Bet365',0, for_stats['Pure_Conversion'])\n",
    "for_stats['Conversion'] = np.where(for_stats['Brand'] == 'Bet365',0, for_stats['Conversion'])\n",
    "\n",
    "# Тут происходит фильтрация если в течении месяца какой то бренд стопнулся\n",
    "\n",
    "# Преобразуем Event_Time в тип datetime64[ns]\n",
    "for_stats['Event_Time'] = pd.to_datetime(for_stats['Event_Time'])\n",
    "\n",
    "# Фильтрация\n",
    "filter_date = pd.to_datetime('2024-12-13')\n",
    "filter_date_from_20 = pd.to_datetime('2025-01-19')\n",
    "filter_date_from_5 = pd.to_datetime('2025-02-04')\n",
    "\n",
    "for_stats = for_stats[~((for_stats['Brand'] == 'Столото') & (for_stats['Event_Time'] < filter_date_from_20))]\n",
    "for_stats = for_stats[~((for_stats['Brand'] == 'KazanExpress') & (for_stats['Event_Time'] > filter_date))]\n",
    "for_stats = for_stats[~((for_stats['Brand'] == 'Фонбет') & (for_stats['Event_Time'] <= filter_date_from_5) \\\n",
    "                        & (for_stats['Event_Name'] == 'af_ftd'))]\n",
    "for_stats = for_stats[~((for_stats['Brand'] == 'Фонбет') & (for_stats['Event_Time'] > filter_date_from_5) \\\n",
    "                        & (for_stats['Event_Name'] == 'af_baseline2'))]\n",
    "\n",
    "\n",
    "# В значениях поля Event_Time оставляем только год месяц и день, без времени\n",
    "for_stats['Event_Time'] = pd.to_datetime(for_stats['Event_Time']).dt.date\n",
    "\n",
    "for_stats['comand_geo'] = np.where(for_stats['geo']== 'RU', 'RU', 'Foreign')\n",
    "\n",
    "for_stats.to_csv(' /sql/state_data/for_stats.csv',encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Данные успешно удалены.\n",
      "Данные успешно обновлены.\n"
     ]
    }
   ],
   "source": [
    "# Тут у нас отрпвляются данные на сервер\n",
    "\n",
    "# Сперва данные оттуда за текущий месяц удаляются=========================================================\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()  # Для работы в Jupyter Notebook\n",
    "\n",
    "# Асинхронная часть: удаление данных\n",
    "async def main():\n",
    "    if mode == 'q':\n",
    "        with SSHTunnelForwarder(    \n",
    "            ('),\n",
    "            ssh_username=\"\",\n",
    "            ssh_password=\"\",\n",
    "            remote_bind_address=('', )\n",
    "        ) as server:\n",
    "            server.start()\n",
    "            local_port = server.\n",
    "            \n",
    "            # Подключение к базе данных через asyncpg\n",
    "            conn = await asyncpg.connect(\n",
    "                database=\"\",\n",
    "                user=\"\",\n",
    "                host=\"\",\n",
    "                password=\"\",\n",
    "                port=local_port\n",
    "            )\n",
    "           \n",
    "            # Удаление данных\n",
    "            async with conn.transaction():\n",
    "                await conn.execute(\n",
    "                    '''\n",
    "                    DELETE FROM \"Stats_new\"\n",
    "                    WHERE DATE_TRUNC('month', \"Event_Time\") = DATE_TRUNC('month', now() - interval '1' day)\n",
    "                    '''\n",
    "                )\n",
    "                print(\"Данные успешно удалены.\")\n",
    "\n",
    "            # Закрытие подключения\n",
    "            await conn.close()\n",
    "        server.stop()\n",
    "\n",
    "# Запуск программы\n",
    "loop = asyncio.get_event_loop()\n",
    "loop.run_until_complete(main())\n",
    "\n",
    "# Затем, второй транзакцией мы данные добавляем =============================================================\n",
    "if mode == 'q':\n",
    "    # Подключение к серверу и базе данных\n",
    "    with SSHTunnelForwarder(\n",
    "        ('', ),  # Remote server IP and SSH port\n",
    "        ssh_username=\"c\",\n",
    "        ssh_password=\"\",\n",
    "        remote_bind_address=('', )\n",
    "    ) as server:\n",
    "\n",
    "        server.start()\n",
    "        \n",
    "        # Получаем локальный порт\n",
    "        local_port = str(server.)\n",
    "        engine = create_engine(f'postgresql:)\n",
    "\n",
    "        # Загрузка новых данных в таблицу\n",
    "        for_stats.to_sql('Stats_new', con=engine, if_exists='append', index=False)\n",
    "\n",
    "        print(\"Данные успешно обновлены.\")\n",
    "\n",
    "    server.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Считается месячная стата\n",
    "for_stats_month = for_stats.groupby(\n",
    "    ['Brand']\n",
    ").agg(\n",
    "    Conversion=('Pure_Conversion', 'sum'),\n",
    "    Fraud=('Fraud', 'sum'),\n",
    "    Budget=('Budget', 'sum'),\n",
    "    Cost=('Cost', 'sum'),\n",
    "    Profit=('Profit', 'sum')\n",
    ").reset_index()\n",
    "# Считаем процент фрода в поле фрод\n",
    "for_stats_month['Fraud'] = (for_stats_month['Fraud'] / for_stats_month['Conversion'])\n",
    "# Считаем Рои\n",
    "for_stats_month['ROI'] = (for_stats_month['Profit'] / for_stats_month['Cost'])\n",
    "# Обрабатываем Рои для бет 365\n",
    "for_stats_month['ROI'].replace([float('inf'), -float('inf')], 0, inplace=True)\n",
    "\n",
    "# Считаем итоги\n",
    "totals = {\n",
    "    'Brand': 'Total',\n",
    "    'Conversion': for_stats_month['Conversion'].sum(),\n",
    "    'Fraud': (for_stats_month['Fraud'] * for_stats_month['Conversion']).sum() / for_stats_month['Conversion'].sum(),\n",
    "    'Budget': for_stats_month['Budget'].sum(),\n",
    "    'Cost': for_stats_month['Cost'].sum(),\n",
    "    'Profit': for_stats_month['Profit'].sum(),\n",
    "    'ROI': for_stats_month['Profit'].sum() / for_stats_month['Cost'].sum()\n",
    "}\n",
    "# Добавляем строку с итогами\n",
    "for_stats_month = pd.concat([for_stats_month, pd.DataFrame([totals])], ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for_stats_ = for_stats[for_stats['Event_Time'] == pd.Timestamp(current_datetime_minus_1_day).date()]\n",
    "print()\n",
    "# Считается стата на прошлый день\n",
    "for_stats_day = for_stats_.groupby(\n",
    "    ['Brand']\n",
    ").agg(\n",
    "    Conversion=('Pure_Conversion', 'sum'),    \n",
    "    Fraud=('Fraud', 'sum'),\n",
    "    Budget=('Budget', 'sum'),\n",
    "    Cost=('Cost', 'sum'),\n",
    "    Profit=('Profit', 'sum')\n",
    ").reset_index()\n",
    "# Считаем процент фрода в поле фрод\n",
    "for_stats_day['Fraud'] = (for_stats_day['Fraud'] / for_stats_day['Conversion'])\n",
    "# Считаем Рои\n",
    "for_stats_day['ROI'] = (for_stats_day['Profit'] / for_stats_day['Cost'])\n",
    "# Обрабатываем Рои для бет 365\n",
    "for_stats_day['ROI'].replace([float('inf'), -float('inf')], 0, inplace=True)\n",
    "\n",
    "totals = {\n",
    "    'Brand': 'Total',\n",
    "    'Conversion': for_stats_day['Conversion'].sum(),\n",
    "    'Fraud': (for_stats_day['Fraud'] * for_stats_day['Conversion']).sum() / for_stats_day['Conversion'].sum(),\n",
    "    'Budget': for_stats_day['Budget'].sum(),\n",
    "    'Cost': for_stats_day['Cost'].sum(),\n",
    "    'Profit': for_stats_day['Profit'].sum(),\n",
    "    'ROI': for_stats_day['Profit'].sum() / for_stats_day['Cost'].sum()\n",
    "}\n",
    "# Добавляем строку с итогами\n",
    "for_stats_day = pd.concat([for_stats_day, pd.DataFrame([totals])], ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "# Считается дневная\n",
    "for_stats_d = for_stats.groupby(\n",
    "    ['Event_Time','Brand']\n",
    ").agg(\n",
    "    Conversion=('Pure_Conversion', 'sum'),\n",
    "    Fraud=('Fraud', 'sum'),\n",
    "    Budget=('Budget', 'sum'),\n",
    "    Cost=('Cost', 'sum'),\n",
    "    Profit=('Profit', 'sum')\n",
    ").reset_index()\n",
    "# Считаем процент фрода в поле фрод\n",
    "for_stats_d['Fraud'] = (for_stats_d['Fraud'] / for_stats_d['Conversion'])\n",
    "# Считаем Рои\n",
    "for_stats_d['ROI'] = (for_stats_d['Profit'] / for_stats_d['Cost'])\n",
    "# Обрабатываем Рои для бет 365\n",
    "for_stats_d['ROI'].replace([float('inf'), -float('inf')], 0, inplace=True)\n",
    "\n",
    "# Выгружаем стату\n",
    "with pd.ExcelWriter(' /sql/state_data/stats.xlsx') as path:\n",
    "    for_stats_month.to_excel(path, sheet_name ='state month', index=False)\n",
    "    for_stats_day.to_excel(path, sheet_name =f'state day {current_datetime_minus_1_day}', index=False)\n",
    "    for_stats_d.to_excel(path, sheet_name ='state everyday', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Считается месячная стата CIS\n",
    "\n",
    "for_stats_CIS = for_stats[for_stats['geo']=='RU']\n",
    "for_stats_month = for_stats_CIS.groupby(\n",
    "    ['Brand']\n",
    ").agg(\n",
    "    Conversion=('Pure_Conversion', 'sum'),\n",
    "    Fraud=('Fraud', 'sum'),\n",
    "    Budget=('Budget', 'sum'),\n",
    "    Cost=('Cost', 'sum'),\n",
    "    Profit=('Profit', 'sum')\n",
    ").reset_index()\n",
    "# Считаем процент фрода в поле фрод\n",
    "for_stats_month['Fraud'] = (for_stats_month['Fraud'] / for_stats_month['Conversion'])\n",
    "# Считаем Рои\n",
    "for_stats_month['ROI'] = (for_stats_month['Profit'] / for_stats_month['Cost'])\n",
    "\n",
    "# Считаем итоги\n",
    "totals = {\n",
    "    'Brand': 'Total',\n",
    "    'Conversion': for_stats_month['Conversion'].sum(),\n",
    "    'Fraud': (for_stats_month['Fraud'] * for_stats_month['Conversion']).sum() / for_stats_month['Conversion'].sum(),\n",
    "    'Budget': for_stats_month['Budget'].sum(),\n",
    "    'Cost': for_stats_month['Cost'].sum(),\n",
    "    'Profit': for_stats_month['Profit'].sum(),\n",
    "    'ROI': for_stats_month['Profit'].sum() / for_stats_month['Cost'].sum()\n",
    "}\n",
    "# Добавляем строку с итогами\n",
    "for_stats_month = pd.concat([for_stats_month, pd.DataFrame([totals])], ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for_stats_ = for_stats_CIS[for_stats_CIS['Event_Time'] == pd.Timestamp(current_datetime_minus_1_day).date()]\n",
    "\n",
    "# Считается стата на прошлый день\n",
    "for_stats_day = for_stats_.groupby(\n",
    "    ['Brand']\n",
    ").agg(\n",
    "    Conversion=('Pure_Conversion', 'sum'),    \n",
    "    Fraud=('Fraud', 'sum'),\n",
    "    Budget=('Budget', 'sum'),\n",
    "    Cost=('Cost', 'sum'),\n",
    "    Profit=('Profit', 'sum')\n",
    ").reset_index()\n",
    "# Считаем процент фрода в поле фрод\n",
    "for_stats_day['Fraud'] = (for_stats_day['Fraud'] / for_stats_day['Conversion'])\n",
    "# Считаем Рои\n",
    "for_stats_day['ROI'] = (for_stats_day['Profit'] / for_stats_day['Cost'])\n",
    "\n",
    "totals = {\n",
    "    'Brand': 'Total',\n",
    "    'Conversion': for_stats_day['Conversion'].sum(),\n",
    "    'Fraud': (for_stats_day['Fraud'] * for_stats_day['Conversion']).sum() / for_stats_day['Conversion'].sum(),\n",
    "    'Budget': for_stats_day['Budget'].sum(),\n",
    "    'Cost': for_stats_day['Cost'].sum(),\n",
    "    'Profit': for_stats_day['Profit'].sum(),\n",
    "    'ROI': for_stats_day['Profit'].sum() / for_stats_day['Cost'].sum()\n",
    "}\n",
    "# Добавляем строку с итогами\n",
    "for_stats_day = pd.concat([for_stats_day, pd.DataFrame([totals])], ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "# Считается дневная\n",
    "for_stats_d = for_stats_CIS.groupby(\n",
    "    ['Event_Time','Brand']\n",
    ").agg(\n",
    "    Conversion=('Pure_Conversion', 'sum'),\n",
    "    Fraud=('Fraud', 'sum'),\n",
    "    Budget=('Budget', 'sum'),\n",
    "    Cost=('Cost', 'sum'),\n",
    "    Profit=('Profit', 'sum')\n",
    ").reset_index()\n",
    "# Считаем процент фрода в поле фрод\n",
    "for_stats_d['Fraud'] = (for_stats_d['Fraud'] / for_stats_d['Conversion'])\n",
    "# Считаем Рои\n",
    "for_stats_d['ROI'] = (for_stats_d['Profit'] / for_stats_d['Cost'])\n",
    "\n",
    "\n",
    "# Выгружаем стату\n",
    "with pd.ExcelWriter(' /sql/state_data/stats_CIS.xlsx') as path:\n",
    "    for_stats_month.to_excel(path, sheet_name ='state month', index=False)\n",
    "    for_stats_day.to_excel(path, sheet_name =f'state day {current_datetime_minus_1_day}', index=False)\n",
    "    for_stats_d.to_excel(path, sheet_name ='state everyday', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Считается месячная стата WW\n",
    "\n",
    "for_stats_WW = for_stats[for_stats['geo']!='RU']\n",
    "for_stats_month = for_stats_WW.groupby(\n",
    "    ['Brand']\n",
    ").agg(\n",
    "    Conversion=('Pure_Conversion', 'sum'),\n",
    "    Fraud=('Fraud', 'sum'),\n",
    "    Budget=('Budget', 'sum'),\n",
    "    Cost=('Cost', 'sum'),\n",
    "    Profit=('Profit', 'sum')\n",
    ").reset_index()\n",
    "# Считаем процент фрода в поле фрод\n",
    "for_stats_month['Fraud'] = (for_stats_month['Fraud'] / for_stats_month['Conversion'])\n",
    "# Считаем Рои\n",
    "for_stats_month['ROI'] = (for_stats_month['Profit'] / for_stats_month['Cost'])\n",
    "# Обрабатываем Рои для бет 365\n",
    "for_stats_month['ROI'].replace([float('inf'), -float('inf')], 0, inplace=True)\n",
    "\n",
    "# Считаем итоги\n",
    "totals = {\n",
    "    'Brand': 'Total',\n",
    "    'Conversion': for_stats_month['Conversion'].sum(),\n",
    "    'Fraud': (for_stats_month['Fraud'] * for_stats_month['Conversion']).sum() / for_stats_month['Conversion'].sum(),\n",
    "    'Budget': for_stats_month['Budget'].sum(),\n",
    "    'Cost': for_stats_month['Cost'].sum(),\n",
    "    'Profit': for_stats_month['Profit'].sum(),\n",
    "    'ROI': for_stats_month['Profit'].sum() / for_stats_month['Cost'].sum()\n",
    "}\n",
    "# Добавляем строку с итогами\n",
    "for_stats_month = pd.concat([for_stats_month, pd.DataFrame([totals])], ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for_stats_ = for_stats_WW[for_stats_WW['Event_Time'] == pd.Timestamp(current_datetime_minus_1_day).date()]\n",
    "\n",
    "# Считается стата на прошлый день\n",
    "for_stats_day = for_stats_.groupby(\n",
    "    ['Brand']\n",
    ").agg(\n",
    "    Conversion=('Pure_Conversion', 'sum'),    \n",
    "    Fraud=('Fraud', 'sum'),\n",
    "    Budget=('Budget', 'sum'),\n",
    "    Cost=('Cost', 'sum'),\n",
    "    Profit=('Profit', 'sum')\n",
    ").reset_index()\n",
    "# Считаем процент фрода в поле фрод\n",
    "for_stats_day['Fraud'] = (for_stats_day['Fraud'] / for_stats_day['Conversion'])\n",
    "# Считаем Рои\n",
    "for_stats_day['ROI'] = (for_stats_day['Profit'] / for_stats_day['Cost'])\n",
    "# Обрабатываем Рои для бет 365\n",
    "for_stats_day['ROI'].replace([float('inf'), -float('inf')], 0, inplace=True)\n",
    "\n",
    "totals = {\n",
    "    'Brand': 'Total',\n",
    "    'Conversion': for_stats_day['Conversion'].sum(),\n",
    "    'Fraud': (for_stats_day['Fraud'] * for_stats_day['Conversion']).sum() / for_stats_day['Conversion'].sum(),\n",
    "    'Budget': for_stats_day['Budget'].sum(),\n",
    "    'Cost': for_stats_day['Cost'].sum(),\n",
    "    'Profit': for_stats_day['Profit'].sum(),\n",
    "    'ROI': for_stats_day['Profit'].sum() / for_stats_day['Cost'].sum()\n",
    "}\n",
    "# Добавляем строку с итогами\n",
    "for_stats_day = pd.concat([for_stats_day, pd.DataFrame([totals])], ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "# Считается дневная\n",
    "for_stats_d = for_stats_WW.groupby(\n",
    "    ['Event_Time','Brand']\n",
    ").agg(\n",
    "    Conversion=('Pure_Conversion', 'sum'),\n",
    "    Fraud=('Fraud', 'sum'),\n",
    "    Budget=('Budget', 'sum'),\n",
    "    Cost=('Cost', 'sum'),\n",
    "    Profit=('Profit', 'sum')\n",
    ").reset_index()\n",
    "# Считаем процент фрода в поле фрод\n",
    "for_stats_d['Fraud'] = (for_stats_d['Fraud'] / for_stats_d['Conversion'])\n",
    "# Считаем Рои\n",
    "for_stats_d['ROI'] = (for_stats_d['Profit'] / for_stats_d['Cost'])\n",
    "# Обрабатываем Рои для бет 365\n",
    "for_stats_d['ROI'].replace([float('inf'), -float('inf')], 0, inplace=True)\n",
    "\n",
    "# Выгружаем стату\n",
    "with pd.ExcelWriter(' /sql/state_data/stats_WW.xlsx') as path:\n",
    "    for_stats_month.to_excel(path, sheet_name ='state month', index=False)\n",
    "    for_stats_day.to_excel(path, sheet_name =f'state day {current_datetime_minus_1_day}', index=False)\n",
    "    for_stats_d.to_excel(path, sheet_name ='state everyday', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "f1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
